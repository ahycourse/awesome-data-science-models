{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Define environment variables</b>\n",
    "\n",
    "To be used in future training steps.  Note that the BUCKET_NAME defined below must exist in the GCP project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env BUCKET_NAME=<ADD DETAILS HERE>\n",
    "%env JOB_NAME=<ADD DETAILS HERE>\n",
    "\n",
    "%env TRAINING_PACKAGE_PATH=./trainer/\n",
    "%env MAIN_TRAINER_MODULE=trainer.rf_trainer\n",
    "%env REGION=<ADD DETAILS HERE>\n",
    "%env RUNTIME_VERSION=<ADD DETAILS HERE>\n",
    "%env PYTHON_VERSION=<ADD DETAILS HERE>\n",
    "%env SCALE_TIER=<ADD DETAILS HERE>\n",
    "\n",
    "%env MODEL_NAME=<ADD DETAILS HERE>\n",
    "%env PROJECT_ID=<ADD DETAILS HERE>\n",
    "%env DATASET_ID=b<ADD DETAILS HERE>\n",
    "%env VERSION_NAME=<ADD DETAILS HERE>\n",
    "%env FRAMEWORK=<ADD DETAILS HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing files must be in a cloud storage bucket before training runs.\n",
    "!gsutil mb gs://${BUCKET_NAME}\n",
    "!gsutil cp train.csv  gs://${BUCKET_NAME}\n",
    "!gsutil cp test.csv  gs://${BUCKET_NAME}\n",
    "    \n",
    "# Remove output from previous runs, if any.\n",
    "!rm input.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Perform training locally with default parameters</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Using AI Platform for Local Training](https://cloud.google.com/sdk/gcloud/reference/ai-platform/local/train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the service account for this project an \"Editor\" role in IAM for all users of this environment\n",
    "# to have Bigquery access. The first time this cell is run, set create-data and hp-tune to True. This\n",
    "# creates input files and the results of hyperparameter tuning available. You can set them to false for \n",
    "# subsequent runs.\n",
    "\n",
    "# Fill the incomplete details to train the model locally\n",
    "\n",
    "!gcloud ai-platform local train \\\n",
    "  --<ADD DETAILS HERE> \\\n",
    "  --<ADD DETAILS HERE> \\\n",
    "  -- \\\n",
    "  --<ADD DETAILS HERE> \\\n",
    "  --<ADD DETAILS HERE> \\\n",
    "  --create-data=True \\\n",
    "  --hp-tune=True \\\n",
    "  --num-hp-iterations=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Perform training on AI Platform</b>\n",
    "\n",
    "The training job can also be run on AI Platform. \n",
    "\n",
    "Important: A single training job (either locally or using AI Platform) must complete with the --create-data  and --hp-tune flags set to True for the remainig functionality to complete.\n",
    "\n",
    "Note that we've updated the compute allocated to the master machine for this job to allow for more muscle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first time this cell is run, set create-data and hp-tune to True. This\n",
    "# creates input files and the results of hyperparameter tuning available. You can set them to false for \n",
    "# subsequent runs.\n",
    "now = !date +\"%Y%m%d_%H%M%S\"\n",
    "%env JOB_NAME=black_friday_job_$now.s\n",
    "\n",
    "!gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --job-dir gs://${BUCKET_NAME}/rf-job-dir \\\n",
    "  --<ADD DETAILS HERE> \\\n",
    "  --<ADD DETAILS HERE> \\\n",
    "  --<ADD DETAILS HERE> \\\n",
    "  --<ADD DETAILS HERE> \\\n",
    "  --<ADD DETAILS HERE> \\\n",
    "  --<ADD DETAILS HERE> \\\n",
    "  --master-machine-type n1-highcpu-16 \\\n",
    "  -- \\\n",
    "  --<ADD DETAILS HERE> \\\n",
    "  --<ADD DETAILS HERE> \\\n",
    "  --<ADD DETAILS HERE> \\\n",
    "  --dataset-id $DATASET_ID \\\n",
    "  --<ADD DETAILS HERE> \\\n",
    "  --<ADD DETAILS HERE> \\\n",
    "  --<ADD DETAILS HERE>\n",
    "    \n",
    "# Stream logs so that training is done before subsequent cells are run.\n",
    "# Remove  '> /dev/null' to see step-by-step output of the model build steps.\n",
    "!gcloud ai-platform jobs stream-logs $JOB_NAME > /dev/null\n",
    "\n",
    "# Model should exit with status \"SUCCEEDED\"\n",
    "!gcloud ai-platform jobs describe $JOB_NAME --format=\"value(state)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Host the trained model on AI Platform</b>\n",
    "\n",
    "Because our raw prediction output from the model is a numpy array that needs to be converted into a product category, we'll need to implement a custom prediction module.\n",
    "\n",
    "First, execute the setup script to create a distribution tarball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python setup.py sdist --formats=gztar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next copy the tarball over to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp dist/trainer-0.1.tar.gz gs://${BUCKET_NAME}/staging-dir/trainer-0.1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new model on AI Platform.  Note that this needs to be done just once, and future iterations are saved as \"versions\" of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the command to create a ML MODEL\n",
    "<ADD DETAILS HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create new version using our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud beta ai-platform versions create $VERSION_NAME \\\n",
    "  --model $MODEL_NAME \\\n",
    "  --origin gs://${BUCKET_NAME}/black_friday_${JOB_NAME}/ \\\n",
    "  --runtime-version=1.14 \\\n",
    "  --python-version=3.5 \\\n",
    "  --package-uris gs://${BUCKET_NAME}/staging-dir/trainer-0.1.tar.gz \\\n",
    "  --prediction-class predictor.MyPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prepare a sample for inference</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate_sample.py \\\n",
    "  --project-id $PROJECT_ID \\\n",
    "  --bucket-name ${BUCKET_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Make an inference on a new sample.</b>\n",
    "\n",
    "Pass the sample object to the model hosted in AI Platform to return a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an online prediction\n",
    "!gcloud ai-platform predict --model $MODEL_NAME --version \\\n",
    "  $VERSION_NAME --json-instances input.json"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
